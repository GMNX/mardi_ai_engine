{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mask Extraction\n",
    "### Import Libraries & Prepare Segment Anything Model(SAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import cv2\n",
    "import numpy as np\n",
    "import yaml\n",
    "\n",
    "# Model SAM\n",
    "from segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor\n",
    "sam_checkpoint = \"../models/sam_vit_h_4b8939.pth\"\n",
    "model_type = \"vit_h\"\n",
    "sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
    "predictor = SamPredictor(sam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare essential functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to display mask in an image\n",
    "def show_mask(mask, color):\n",
    "    h, w = mask.shape[-2:]\n",
    "    mask_image = (mask.reshape(h, w, 1) * np.array(color)).astype(np.uint8)\n",
    "    return mask_image\n",
    "\n",
    "# Function for displaying bounding box and text in an image\n",
    "def show_box(image, box, label, conf_score, color):\n",
    "    x0, y0 = int(box[0]), int(box[1])\n",
    "    x1, y1 = int(box[2]), int(box[3])\n",
    "    cv2.rectangle(image, (x0, y0), (x1, y1), color, 2)\n",
    "    label_text = f'{label} {conf_score:.2f}'\n",
    "    cv2.putText(image, label_text, (x0, y0 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "# Load class names from YAML file\n",
    "with open('../yolov9/data/coco.yaml', 'r') as file:\n",
    "    coco_data = yaml.safe_load(file)\n",
    "    class_names = coco_data['names']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['../yolov9/weights/gelan-c.pt'], source=../images, data=../yolov9/data/coco128.yaml, imgsz=[640, 640], conf_thres=0.1, iou_thres=0.45, max_det=1000, device=0, view_img=False, save_txt=True, save_conf=True, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=/data/notebook, name=mardi, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "YOLOv5 ðŸš€ 1e33dbb Python-3.10.8 torch-1.13.1 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 5938MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 467 layers, 25472640 parameters, 0 gradients, 102.8 GFLOPs\n",
      "image 1/5 /data/images/week_1.jpg: 480x640 2 traffic lights, 1 potted plant, 1 vase, 18.0ms\n",
      "image 2/5 /data/images/week_2.jpg: 480x640 2 traffic lights, 1 umbrella, 1 potted plant, 1 vase, 17.9ms\n",
      "image 3/5 /data/images/week_3.jpg: 480x640 2 traffic lights, 1 potted plant, 1 cell phone, 1 vase, 17.9ms\n",
      "image 4/5 /data/images/week_4.jpg: 480x640 1 umbrella, 17.9ms\n",
      "image 5/5 /data/images/week_5.jpg: 480x640 2 potted plants, 17.9ms\n",
      "Speed: 0.3ms pre-process, 17.9ms inference, 0.5ms NMS per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1m/data/notebook/mardi\u001b[0m\n",
      "5 labels saved to /data/notebook/mardi/labels\n"
     ]
    }
   ],
   "source": [
    "# Define the desired classes\n",
    "desired_classes = [25, 58]\n",
    "\n",
    "# Random color map for each class\n",
    "color_map = {}\n",
    "for class_id in desired_classes:\n",
    "    color_map[class_id] = tuple(np.random.randint(0, 256, 3).tolist())\n",
    "\n",
    "# Directory where the images are located\n",
    "images_dir = '../images'\n",
    "\n",
    "# Directory where the tags (detections) are located\n",
    "project_path = '/data/notebook'\n",
    "trial_name = 'mardi'\n",
    "yolo_result_path = f'{project_path}/{trial_name}/'\n",
    "labels_dir = f'{yolo_result_path}/labels/'\n",
    "if os.path.exists(yolo_result_path):\n",
    "    shutil.rmtree(yolo_result_path)\n",
    "\n",
    "# Directory for saving processed images\n",
    "output_dir = 'mask_extraction'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Get the list of image file names in the directory\n",
    "image_files = os.listdir(images_dir)\n",
    "\n",
    "# Detection using the gelan-c model\n",
    "!python ../yolov9/detect.py --weights ../yolov9/weights/gelan-c.pt --conf 0.1 --source {images_dir} --project {project_path} --name {trial_name} --device 0 --save-txt --save-conf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate masked data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed image saved in mask_extraction/week_1.jpg\n",
      "Processed image saved in mask_extraction/week_2.jpg\n",
      "Processed image saved in mask_extraction/week_3.jpg\n",
      "Processed image saved in mask_extraction/week_4.jpg\n",
      "Processed image saved in mask_extraction/week_5.jpg\n",
      "Image processing and saving completed.\n"
     ]
    }
   ],
   "source": [
    "# Iterate on images\n",
    "for image_file in image_files:\n",
    "    # Build the complete image path\n",
    "    image_path = os.path.join(images_dir, image_file)\n",
    "\n",
    "    # Read the image\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"Error: Unable to load image {image_path}\")\n",
    "        continue\n",
    "\n",
    "    image_height, image_width, _ = image.shape\n",
    "\n",
    "    # Set the image for the predictor\n",
    "    predictor.set_image(image)\n",
    "\n",
    "    # Construct the full path to the label file for this image\n",
    "    label_file = os.path.splitext(image_file)[0] + '.txt'\n",
    "    label_path = os.path.join(labels_dir, label_file)\n",
    "\n",
    "    if not os.path.exists(label_path):\n",
    "        print(f\"Warning: Tag file not found for {image_file}\")\n",
    "        continue\n",
    "\n",
    "    class_ids = []\n",
    "    bboxes = []\n",
    "    conf_scores = []\n",
    "\n",
    "    # Read the tag file\n",
    "    with open(label_path, 'r') as file:\n",
    "        for line in file:\n",
    "            components = line.split()\n",
    "            class_id = int(components[0])\n",
    "            confidence = float(components[5])\n",
    "            cx, cy, w, h = [float(x) for x in components[1:5]]\n",
    "\n",
    "            # Convert from normalized [0, 1] to image scale\n",
    "            cx *= image_width\n",
    "            cy *= image_height\n",
    "            w *= image_width\n",
    "            h *= image_height\n",
    "\n",
    "            # Convert center x, y, width and height to xmin, ymin, xmax, ymax\n",
    "            xmin = cx - w / 2\n",
    "            ymin = cy - h / 2\n",
    "            xmax = cx + w / 2\n",
    "            ymax = cy + h / 2\n",
    "\n",
    "            class_ids.append(class_id)\n",
    "            bboxes.append((xmin, ymin, xmax, ymax))\n",
    "            conf_scores.append(confidence)\n",
    "\n",
    "    # Create an added mask for the image\n",
    "    aggregate_mask = np.zeros(image.shape[:2], dtype=np.uint8)\n",
    "\n",
    "    # Iterate on each detection and process it into the image\n",
    "    for class_id, bbox, conf_score in zip(class_ids, bboxes, conf_scores):\n",
    "        if class_id in desired_classes:\n",
    "            class_name = class_names[class_id]\n",
    "            color = color_map[class_id]\n",
    "            show_box(image, bbox, class_name, conf_score, color)\n",
    "\n",
    "            # Generate and accumulate masks for each bounding box\n",
    "            input_box = np.array(bbox).reshape(1, 4)\n",
    "            masks, _, _ = predictor.predict(\n",
    "                point_coords=None,\n",
    "                point_labels=None,\n",
    "                box=input_box,\n",
    "                multimask_output=False,\n",
    "            )\n",
    "            aggregate_mask = np.where(masks[0] > 0.5, 1, aggregate_mask)\n",
    "\n",
    "    # Convert the aggregated segmentation mask to a binary mask\n",
    "    binary_mask = np.where(aggregate_mask == 1, 1, 0)\n",
    "\n",
    "    # Create a white background with the same size as the image\n",
    "    white_background = np.ones_like(image) * 255\n",
    "\n",
    "    # Applying the binary mask to the original image\n",
    "    # Where the binary mask is 0 (background), use white background; otherwise, use the original image.\n",
    "    new_image = white_background * (1 - binary_mask[..., np.newaxis]) + image * binary_mask[..., np.newaxis]\n",
    "\n",
    "    # Save the processed image with white background in the output directory\n",
    "    output_image_path = os.path.join(output_dir, image_file)\n",
    "    cv2.imwrite(output_image_path, new_image.astype(np.uint8))\n",
    "    print(f\"Processed image saved in {output_image_path}\")\n",
    "\n",
    "print(\"Image processing and saving completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
